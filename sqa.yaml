# Quick helper to re-run only failed or not-yet-run tests:
#   python3 tools/sqa_runner.py run --plan main --failed-missing --plan-file sqa.yaml
version: 1
tests:
  # 3.0 Environment & Documentation Validation
  - id: EN-001
    category: environment
    name: python env is complete
    steps:
      - Ensure environment is configured in .env (LEANYOLO_WEIGHTS_DIR/CACHE_DIR), fail test if not.
      - If .venv is missing, create it via: python -m venv .venv; otherwise reuse it.
      - ./.venv/bin/python -m pip install --upgrade pip
      - ./.venv/bin/python -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
      - ./.venv/bin/python -m pip install -r requirements.txt
      - ./.venv/bin/python tools/check_imports.py
      - On success, print: TEST STATUS: PASSED
    expected: Prints OK and exits 0; all imports are satisfied; no sudo required.
 
  # 3.1 Unit Tests (consolidated)
  - id: UT-100
    category: unit
    name: Unit tests (CPU non-fidelity)
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Set CUDA_VISIBLE_DEVICES="" and OMP_NUM_THREADS=1 for stability
      - ./.venv/bin/python -m pytest -q -m "not fidelity"
      - On success, print: TEST STATUS: PASSED
    expected: All non-fidelity unit tests pass on CPU (no failures)

  - id: UT-101
    category: unit
    name: Unit tests (GPU full)
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Check for CUDA availability (torch.cuda.is_available() and device_count>0); if not available, print TEST STATUS: PASSED (SKIPPED: no CUDA) and exit
      - Set OMP_NUM_THREADS=1 for stability
      - ./.venv/bin/python -m pytest -q -m "not fidelity"
      - ./.venv/bin/python -m pytest -q -m fidelity
      - On success, print: TEST STATUS: PASSED
    expected: All unit tests pass on GPU; if no CUDA is visible, test is treated as skipped and passes.

  # 3.2 Functional Tests for Tools
  - id: FT-001
    category: functional
    name: prepare_aquarium (basic)
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Unzip AquariumDataset.zip to raw and prepare to data/aquarium
      - Run: ./.venv/bin/python tools/prepare_aquarium.py --zip data/AquariumDataset.zip --root data/aquarium --clean
      - On success, print: TEST STATUS: PASSED
    expected: COCO-style folder structure produced; train.json/val.json written.

  - id: FT-002
    category: functional
    name: prepare_aquarium (keep extract)
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Run: ./.venv/bin/python tools/prepare_aquarium.py --zip data/AquariumDataset.zip --root data/aquarium --clean --keep-extract
      - Verify: data/aquarium/raw_extracted directory exists afterwards
      - On success, print: TEST STATUS: PASSED
    expected: raw_extracted folder retained after prepare.

  - id: FT-003
    category: functional
    name: tools/train.py
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Create a tiny COCO dataset (1–2 images) in a temp dir
      - Run: ./.venv/bin/python tools/train.py --train-images <tmp>/images --train-ann <tmp>/ann.json --device cpu --weights none --imgsz 64 --epochs 1 --batch-size 1 --workers 0 --no-tqdm --save-dir runs/train/ft-003
      - Verify: runs/train/ft-003/ckpt.pt exists and at least one epoch*.pt
      - On success, print: TEST STATUS: PASSED
    expected: Checkpoint and log files appear in runs/train/* for a 1‑epoch CPU run on a tiny dataset.

  - id: FT-004
    category: functional
    name: tools/val.py
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Create or reuse a tiny COCO dataset (1 image)
      - Run: ./.venv/bin/python tools/val.py --images <tmp>/images --ann <tmp>/ann.json --weights none --device cpu --imgsz 64 --max-images 1 --save-json runs/val/ft-004.json
      - Verify: runs/val/ft-004.json exists and console printed mAP50-95
      - On success, print: TEST STATUS: PASSED
    expected: JSON detections file saved and console summary shows mAP metrics for a 1‑image CPU run.

  - id: FT-005
    category: functional
    name: tools/infer.py
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Run on dog.jpg with pretrained weights
    expected: Output image saved to runs/infer/*; console lists detections

  - id: FT-006
    category: functional
    name: tools/transfer_learn_aquarium.py
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Train for 3 epochs on Aquarium data
    expected: Log shows decreasing loss; new checkpoint saved

  - id: FT-007
    category: functional
    name: tools/download_all_pretrained.py
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Execute tools/download_all_pretrained.py without arguments
    expected: All six YOLOv10 weight files downloaded

  - id: FT-008
    category: functional
    name: tools/convert_official_weights.py
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Convert official checkpoint to lean format
      - Load converted .pt with get_model
    expected: Converted .pt loads successfully

  # 3.3 Integration Tests (Full Cycle)
  - id: IT-001
    category: integration
    name: Baseline train→val→infer
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Prepare dataset
      - Run tools/train.py for 1–2 epochs
      - Run tools/val.py
      - Run tools/infer.py on sample image
    expected: Training completes; validation JSON shows expected mAP; inference outputs annotated image

  - id: IT-002
    category: integration
    name: Transfer learning loop
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Run tools/prepare_aquarium.py
      - Run tools/transfer_learn_aquarium.py for ≥5 epochs (CPU-safe flags: --device cpu --workers 0 --no-tqdm; use --weights none if pretrained weights are unavailable)
      - Run tools/val.py on the same dataset (CPU-safe flags)
      - On success, print: TEST STATUS: PASSED
    expected: Training completes and validation runs; if a baseline from IT-001 is available and datasets align, report any improvement; otherwise pass if train+val succeeded without errors.

  - id: IT-003
    category: integration
    name: Weight conversion + evaluation
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Convert official weights to lean format
      - Load with tools/val.py
      - Check mAP parity vs official results
    expected: mAP within ±0.5 of official reference

  - id: IT-004
    category: integration
    name: Map parity checker
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Run tools/check_map_parity.py after inference and validation
    expected: Report indicates parity across model sizes
