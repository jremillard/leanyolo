# Quick helper to re-run only failed or not-yet-run tests:
#   python3 tools/sqa_runner.py run --plan main --failed-missing --plan-file sqa.yaml
version: 1
tests:
  # 3.0 Environment & Documentation Validation
  - id: EN-001
    category: environment
    name: python env is complete
    steps:
      - Remove existing .venv directory
      - python -m venv .venv
      - ./.venv/bin/python -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
      - ./.venv/bin/python -m pip install -r requirements.txt
      - ./.venv/bin/python tools/check_imports.py
    expected: Prints "OK" and exits 0; all imports are satisfied, no sudo needed.
 
  # 3.1 Unit Tests (consolidated)
  - id: UT-100
    category: unit
    name: Unit tests (CPU full)
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Set CUDA_VISIBLE_DEVICES=""
      - ./.venv/bin/python -m pytest -q -m "not fidelity"
      - ./.venv/bin/python -m pytest -q -m fidelity
    expected: All unit tests pass on CPU (no failures)

  - id: UT-101
    category: unit
    name: Unit tests (GPU full)
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Ensure at least one CUDA device is visible
      - ./.venv/bin/python -m pytest -q -m "not fidelity"
      - ./.venv/bin/python -m pytest -q -m fidelity
    expected: All unit tests pass on GPU (no failures)

  # 3.2 Functional Tests for Tools
  - id: FT-001
    category: functional
    name: prepare_aquarium (basic)
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Unzip AquariumDataset.zip to raw and prepare to data/aquarium
      - Run: ./.venv/bin/python tools/prepare_acquirium.py --zip data/AquariumDataset.zip --root data/aquarium --clean
    expected: COCO-style folder structure produced; train.json/val.json written

  - id: FT-002
    category: functional
    name: prepare_aquarium (keep extract)
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Run: ./.venv/bin/python tools/prepare_acquirium.py --zip data/AquariumDataset.zip --root data/aquarium --clean --keep-extract
    expected: raw_extracted folder retained after prepare

  - id: FT-003
    category: functional
    name: tools/train.py
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Train on a small dataset for 1 epoch with --batch-size 2
    expected: Checkpoint and log files appear in runs/train/*

  - id: FT-004
    category: functional
    name: tools/val.py
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Validate pretrained model on a small dataset
    expected: JSON results and console summary generated

  - id: FT-005
    category: functional
    name: tools/infer.py
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Run on dog.jpg with pretrained weights
    expected: Output image saved to runs/infer/*; console lists detections

  - id: FT-006
    category: functional
    name: tools/transfer_learn_aquarium.py
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Train for 3 epochs on Aquarium data
    expected: Log shows decreasing loss; new checkpoint saved

  - id: FT-007
    category: functional
    name: tools/download_all_pretrained.py
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Execute tools/download_all_pretrained.py without arguments
    expected: All six YOLOv10 weight files downloaded

  - id: FT-008
    category: functional
    name: tools/convert_official_weights.py
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Convert official checkpoint to lean format
      - Load converted .pt with get_model
    expected: Converted .pt loads successfully

  # 3.3 Integration Tests (Full Cycle)
  - id: IT-001
    category: integration
    name: Baseline train→val→infer
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Prepare dataset
      - Run tools/train.py for 1–2 epochs
      - Run tools/val.py
      - Run tools/infer.py on sample image
    expected: Training completes; validation JSON shows expected mAP; inference outputs annotated image

  - id: IT-002
    category: integration
    name: Transfer learning loop
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Run tools/prepare_aquarium.py
      - Run tools/transfer_learn_aquarium.py for ≥5 epochs
      - Run tools/val.py
    expected: Validation mAP improves vs. baseline recorded in IT-001

  - id: IT-003
    category: integration
    name: Weight conversion + evaluation
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Convert official weights to lean format
      - Load with tools/val.py
      - Check mAP parity vs official results
    expected: mAP within ±0.5 of official reference

  - id: IT-004
    category: integration
    name: Map parity checker
    steps:
      - Ensure environment is setup correctly in .env, fail test if not.
      - ./.venv/bin/python tools/check_imports.py
      - Run tools/check_map_parity.py after inference and validation
    expected: Report indicates parity across model sizes
